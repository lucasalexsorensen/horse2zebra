{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "deadly-watson",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The code will run on GPU.\n"
     ]
    }
   ],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "from tqdm.notebook import tqdm\n",
    "import os\n",
    "import numpy as np\n",
    "import glob\n",
    "import PIL.Image as Image\n",
    "from tqdm.notebook import tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(\"The code will run on GPU.\")\n",
    "else:\n",
    "    print(\"The code will run on CPU. Go to Edit->Notebook Settings and choose GPU as the hardware accelerator\")\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acoustic-needle",
   "metadata": {},
   "source": [
    "# Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "lesbian-resource",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, transform, data_path='horse2zebra'):\n",
    "        self.transform = transform\n",
    "        self.A_paths = sum([glob.glob('%s/%s%s/*.jpg' % (data_path, split, 'A')) for split in ['test', 'train']], [])\n",
    "        self.B_paths = sum([glob.glob('%s/%s%s/*.jpg' % (data_path, split, 'B')) for split in ['test', 'train']], [])\n",
    "        assert len(self.A_paths) == len(self.B_paths)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.A_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        A = Image.open(self.A_paths[idx]).convert('RGB')\n",
    "        B = Image.open(self.B_paths[idx]).convert('RGB')\n",
    "        return self.transform(A), self.transform(B)\n",
    "\n",
    "transform = transforms.ToTensor()\n",
    "\n",
    "dataset = MyDataset(transform)\n",
    "\n",
    "batch_size = 1\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "completed-token",
   "metadata": {},
   "outputs": [],
   "source": [
    "#A, B = next(iter(dataloader))\n",
    "#\n",
    "#plt.figure()\n",
    "#\n",
    "#fix_axis = lambda im: np.swapaxes(np.swapaxes(im, 0, 2), 0, 1)\n",
    "#\n",
    "#plt.subplot(1,2,1)\n",
    "#plt.imshow(fix_axis(A))\n",
    "#plt.axis('off')\n",
    "#plt.subplot(1,2,2)\n",
    "#plt.imshow(fix_axis(B))\n",
    "#plt.axis('off')\n",
    "#plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "quarterly-royalty",
   "metadata": {},
   "source": [
    "# Model definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "declared-bearing",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNetBlock(nn.Module):\n",
    "    def __init__(self, n_features=32):\n",
    "        super(ResNetBlock, self).__init__()\n",
    "        self.convolutional = nn.Sequential(\n",
    "            nn.Conv2d(n_features, n_features, 3, padding=1, stride=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(n_features, n_features, 3, padding=1, stride=1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.convolutional(x)\n",
    "        out += x\n",
    "        out = F.relu(out)\n",
    "        return out\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, n_resblocks=5):\n",
    "        super().__init__()\n",
    "\n",
    "        self.encoding = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, 7, stride=1, padding=3),   # 256 -> 256\n",
    "            nn.InstanceNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 128, 3, stride=2, padding=1),  # 256 -> 128\n",
    "            nn.InstanceNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(128, 256, 3, stride=2, padding=1),  # 128 -> 64\n",
    "            nn.InstanceNorm2d(256),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        self.resnet = nn.Sequential(\n",
    "            *[ResNetBlock(n_features=256) for _ in range(n_resblocks)]\n",
    "        )\n",
    "\n",
    "        self.decoding = nn.Sequential(\n",
    "            nn.ConvTranspose2d(256, 128, 3, stride=2, padding=1, output_padding=1),\n",
    "            nn.InstanceNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(128, 64, 3, stride=2, padding=1, output_padding=1),\n",
    "            nn.InstanceNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(64, 3, 7, stride=1, padding=3),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoding(x)\n",
    "        x = self.resnet(x)\n",
    "        x = self.decoding(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, leak=0.2):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, 4, stride=2, padding=1),  # 256 -> 128\n",
    "            nn.InstanceNorm2d(64),\n",
    "            nn.LeakyReLU(leak),\n",
    "            nn.Conv2d(64, 128, 4, stride=2, padding=1),  # 128 -> 64\n",
    "            nn.InstanceNorm2d(128),\n",
    "            nn.LeakyReLU(leak),\n",
    "            nn.Conv2d(128, 256, 4, stride=2, padding=1),  # 64 -> 32\n",
    "            nn.InstanceNorm2d(256),\n",
    "            nn.LeakyReLU(leak),\n",
    "            nn.Conv2d(256, 512, 4, stride=1, padding=1),  # 32 -> 31\n",
    "            nn.InstanceNorm2d(512),\n",
    "            nn.LeakyReLU(leak),\n",
    "            nn.Conv2d(512, 1, 4, stride=1, padding=1), # 31 -> 30\n",
    "            nn.LogSoftmax(dim=0),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        return x\n",
    "\n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "alike-geography",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded all models to GPU memory!!\n"
     ]
    }
   ],
   "source": [
    "# initialize models in memory\n",
    "A2B = Generator()\n",
    "B2A = Generator()\n",
    "D_A = Discriminator()\n",
    "D_B = Discriminator()\n",
    "\n",
    "A2B.cuda()\n",
    "B2A.cuda()\n",
    "D_A.cuda()\n",
    "D_B.cuda()\n",
    "\n",
    "from utils import weights_init_normal\n",
    "A2B.apply(weights_init_normal)\n",
    "B2A.apply(weights_init_normal)\n",
    "D_A.apply(weights_init_normal)\n",
    "D_B.apply(weights_init_normal)\n",
    "print('loaded all models to GPU memory!!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mediterranean-tattoo",
   "metadata": {},
   "source": [
    "# Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "grave-moses",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "from torch.autograd import Variable\n",
    "from utils import Logger, ReplayBuffer, LambdaLR\n",
    "Tensor = torch.cuda.FloatTensor\n",
    "\n",
    "# EPOCHS !!\n",
    "epochs = 100\n",
    "decay_after_epochs = 50\n",
    "\n",
    "\n",
    "# Losses\n",
    "criterion_GAN = torch.nn.MSELoss()\n",
    "criterion_cycle = torch.nn.L1Loss()\n",
    "criterion_identity = torch.nn.L1Loss()\n",
    "\n",
    "LR = 0.0002\n",
    "\n",
    "optimizer_G = torch.optim.Adam(itertools.chain(A2B.parameters(), B2A.parameters()), lr=LR, betas=(0.5, 0.999))\n",
    "optimizer_D_A = torch.optim.Adam(D_A.parameters(), lr=LR, betas=(0.5, 0.999))\n",
    "optimizer_D_B = torch.optim.Adam(D_B.parameters(), lr=LR, betas=(0.5, 0.999))\n",
    "\n",
    "# LR schedulers\n",
    "lr_scheduler_G = torch.optim.lr_scheduler.LambdaLR(optimizer_G, lr_lambda=LambdaLR(epochs, 0, decay_after_epochs).step)\n",
    "lr_scheduler_D_A = torch.optim.lr_scheduler.LambdaLR(optimizer_D_A, lr_lambda=LambdaLR(epochs, 0, decay_after_epochs).step)\n",
    "lr_scheduler_D_B = torch.optim.lr_scheduler.LambdaLR(optimizer_D_B, lr_lambda=LambdaLR(epochs, 0, decay_after_epochs).step)\n",
    "\n",
    "# buffer variables (to be overriden and used during training)\n",
    "#input_A = Tensor(batch_size, 3, 256, 256)\n",
    "#input_B = Tensor(batch_size, 3, 256, 256)\n",
    "target_real = Variable(Tensor(batch_size).fill_(1.0), requires_grad=False)\n",
    "target_fake = Variable(Tensor(batch_size).fill_(0.0), requires_grad=False)\n",
    "fake_A_buffer = ReplayBuffer()\n",
    "fake_B_buffer = ReplayBuffer()\n",
    "\n",
    "# progress logger\n",
    "logger = Logger(epochs, len(dataloader))\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    for i, batch in enumerate(dataloader):\n",
    "        real_A = Variable(torch.tensor(batch[0]).to(device))\n",
    "        real_B = Variable(torch.tensor(batch[1]).to(device))\n",
    "\n",
    "        # for generators A & B\n",
    "        optimizer_G.zero_grad()\n",
    "\n",
    "        # Identity loss\n",
    "        # G_A2B(B) should equal B if real B is fed\n",
    "        same_B = A2B(real_B)\n",
    "        loss_identity_B = criterion_identity(same_B, real_B)*5.0\n",
    "        # G_B2A(A) should equal A if real A is fed\n",
    "        same_A = B2A(real_A)\n",
    "        loss_identity_A = criterion_identity(same_A, real_A)*5.0\n",
    "\n",
    "        # GAN loss\n",
    "        fake_B = A2B(real_A)\n",
    "        pred_fake = D_B(fake_B)\n",
    "        loss_GAN_A2B = criterion_GAN(pred_fake, target_real)\n",
    "\n",
    "        fake_A = B2A(real_B)\n",
    "        pred_fake = D_A(fake_A)\n",
    "        loss_GAN_B2A = criterion_GAN(pred_fake, target_real)\n",
    "\n",
    "        # Cycle loss\n",
    "        recovered_A = B2A(fake_B)\n",
    "        loss_cycle_ABA = criterion_cycle(recovered_A, real_A)*10.0\n",
    "\n",
    "        recovered_B = A2B(fake_A)\n",
    "        loss_cycle_BAB = criterion_cycle(recovered_B, real_B)*10.0\n",
    "\n",
    "        # Total loss\n",
    "        loss_G = loss_identity_A + loss_identity_B + loss_GAN_A2B + loss_GAN_B2A + loss_cycle_ABA + loss_cycle_BAB\n",
    "        loss_G.backward()\n",
    "        \n",
    "        optimizer_G.step()\n",
    "        ###################################\n",
    "\n",
    "        ###### Discriminator A ######\n",
    "        optimizer_D_A.zero_grad()\n",
    "\n",
    "        # Real loss\n",
    "        pred_real = D_A(real_A)\n",
    "        loss_D_real = criterion_GAN(pred_real, target_real)\n",
    "\n",
    "        # Fake loss\n",
    "        fake_A = fake_A_buffer.push_and_pop(fake_A)\n",
    "        pred_fake = D_A(fake_A.detach())\n",
    "        loss_D_fake = criterion_GAN(pred_fake, target_fake)\n",
    "\n",
    "        # Total loss\n",
    "        loss_D_A = (loss_D_real + loss_D_fake)*0.5\n",
    "        loss_D_A.backward()\n",
    "\n",
    "        optimizer_D_A.step()\n",
    "        ###################################\n",
    "\n",
    "        ###### Discriminator B ######\n",
    "        optimizer_D_B.zero_grad()\n",
    "\n",
    "        # Real loss\n",
    "        pred_real = D_B(real_B)\n",
    "        loss_D_real = criterion_GAN(pred_real, target_real)\n",
    "        \n",
    "        # Fake loss\n",
    "        fake_B = fake_B_buffer.push_and_pop(fake_B)\n",
    "        pred_fake = D_B(fake_B.detach())\n",
    "        loss_D_fake = criterion_GAN(pred_fake, target_fake)\n",
    "\n",
    "        # Total loss\n",
    "        loss_D_B = (loss_D_real + loss_D_fake)*0.5\n",
    "        loss_D_B.backward()\n",
    "\n",
    "        optimizer_D_B.step()\n",
    "        ###################################\n",
    "\n",
    "        # Progress report (http://localhost:8097)\n",
    "        logger.log({'loss_G': loss_G, 'loss_G_identity': (loss_identity_A + loss_identity_B), 'loss_G_GAN': (loss_GAN_A2B + loss_GAN_B2A),\n",
    "                    'loss_G_cycle': (loss_cycle_ABA + loss_cycle_BAB), 'loss_D': (loss_D_A + loss_D_B)}, \n",
    "                    images={'real_A': real_A, 'real_B': real_B, 'fake_A': fake_A, 'fake_B': fake_B})\n",
    "    # Update learning rates\n",
    "    lr_scheduler_G.step()\n",
    "    lr_scheduler_D_A.step()\n",
    "    lr_scheduler_D_B.step()\n",
    "\n",
    "    # Save models checkpoints\n",
    "    torch.save(A2B.state_dict(), 'output/A2B.pth')\n",
    "    torch.save(B2A.state_dict(), 'output/B2A.pth')\n",
    "    torch.save(A.state_dict(), 'output/A.pth')\n",
    "    torch.save(B.state_dict(), 'output/B.pth')\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "charming-termination",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "incorporate-ecology",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "brazilian-france",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "starting-fireplace",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2db524e06e9f5f4ffedc911c917cb75e12dbc923643829bf417064a77eb14d37"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
